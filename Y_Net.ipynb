{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Y-net for depth estimation\n",
    "\n",
    "### This notebook contains code to run a new depth estimation model called Y-net\n",
    "Done By:\n",
    "Chandravaran Kunjeti\n",
    "Saikumar Dande"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iKdJJXQgM5U1",
    "outputId": "de66eb8f-5687-405c-e3a6-79b355ac6e29"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting albumentations==0.4.6\n",
      "  Downloading albumentations-0.4.6.tar.gz (117 kB)\n",
      "\u001b[K     |████████████████████████████████| 117 kB 11.6 MB/s \n",
      "\u001b[?25hRequirement already satisfied: numpy>=1.11.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.19.5)\n",
      "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (1.4.1)\n",
      "Collecting imgaug>=0.4.0\n",
      "  Downloading imgaug-0.4.0-py2.py3-none-any.whl (948 kB)\n",
      "\u001b[K     |████████████████████████████████| 948 kB 36.9 MB/s \n",
      "\u001b[?25hRequirement already satisfied: PyYAML in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (3.13)\n",
      "Requirement already satisfied: opencv-python>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from albumentations==0.4.6) (4.1.2.30)\n",
      "Requirement already satisfied: scikit-image>=0.14.2 in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (0.18.3)\n",
      "Requirement already satisfied: Shapely in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.8.0)\n",
      "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (3.2.2)\n",
      "Requirement already satisfied: imageio in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (2.4.1)\n",
      "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (7.1.2)\n",
      "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from imgaug>=0.4.0->albumentations==0.4.6) (1.15.0)\n",
      "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (1.2.0)\n",
      "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2021.11.2)\n",
      "Requirement already satisfied: networkx>=2.0 in /usr/local/lib/python3.7/dist-packages (from scikit-image>=0.14.2->imgaug>=0.4.0->albumentations==0.4.6) (2.6.3)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (1.3.2)\n",
      "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (0.11.0)\n",
      "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (3.0.6)\n",
      "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->imgaug>=0.4.0->albumentations==0.4.6) (2.8.2)\n",
      "Building wheels for collected packages: albumentations\n",
      "  Building wheel for albumentations (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
      "  Created wheel for albumentations: filename=albumentations-0.4.6-py3-none-any.whl size=65172 sha256=1c460bcf785b694acd246645a7bdc119e7e9480145fa4c36d4e1f4250eff73cf\n",
      "  Stored in directory: /root/.cache/pip/wheels/cf/34/0f/cb2a5f93561a181a4bcc84847ad6aaceea8b5a3127469616cc\n",
      "Successfully built albumentations\n",
      "Installing collected packages: imgaug, albumentations\n",
      "  Attempting uninstall: imgaug\n",
      "    Found existing installation: imgaug 0.2.9\n",
      "    Uninstalling imgaug-0.2.9:\n",
      "      Successfully uninstalled imgaug-0.2.9\n",
      "  Attempting uninstall: albumentations\n",
      "    Found existing installation: albumentations 0.1.12\n",
      "    Uninstalling albumentations-0.1.12:\n",
      "      Successfully uninstalled albumentations-0.1.12\n",
      "Successfully installed albumentations-0.4.6 imgaug-0.4.0\n"
     ]
    }
   ],
   "source": [
    "!pip install albumentations==0.4.6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AjhntKacJO7s",
    "outputId": "80b6402c-5ff9-43c2-8be6-1b221a3786ef"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive', force_remount=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "l8QDh0z9OsBN",
    "outputId": "87bc4703-ff01-4377-f953-d56557d60380"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Neural Network Project\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/Neural\\ Network\\ Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lvIlIPM5Nbrx"
   },
   "outputs": [],
   "source": [
    "from DataLoader import TransposeDepthInput, NYUDataset, save_checkpoint, get_loaders, save_predictions_as_imgs\n",
    "from metrics import ScaleInvariantLoss, threeshold_percentage, rmse_linear, rmse_log, abs_relative_difference, squared_relative_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iuTQGWdupqnt"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from Ynet import YNET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-etyVshYi_on",
    "outputId": "234db995-d565-4873-96e6-aa78e0c114f0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape\t: torch.Size([3, 3, 120, 160])\n",
      "Gradient shape\t: torch.Size([3, 2, 120, 160])\n",
      "Output shape\t: torch.Size([3, 1, 120, 160])\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    image = torch.randn((3, 3, 120, 160))\n",
    "    gradient = torch.randn((3, 2, 120, 160))\n",
    "    model = YNET(in_channels1=3, in_channels2=2, out_channels=1)\n",
    "    preds = model(image, gradient)\n",
    "    print(\"Input shape\\t:\", image.shape)\n",
    "    print(\"Gradient shape\\t:\", gradient.shape)\n",
    "    print(\"Output shape\\t:\", preds.shape)\n",
    "    assert preds.shape[2:] == image.shape[2:]\n",
    "\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3f_UsHLIoOAG"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "from tqdm import tqdm\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import math\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "# Hyperparameters etc.\n",
    "LEARNING_RATE = 1e-4\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "BATCH_SIZE = 16\n",
    "NUM_EPOCHS = 100\n",
    "NUM_WORKERS = 16\n",
    "PIN_MEMORY = True\n",
    "LOAD_MODEL = False\n",
    "TRAIN_IMG_DIR = \"Datasets/Train/images/\"\n",
    "TRAIN_DEPTH_DIR = \"Datasets/Train/depths/\"\n",
    "VAL_IMG_DIR = \"Datasets/Validation/images/\"\n",
    "VAL_DEPTH_DIR = \"Datasets/Validation/depths/\"\n",
    "TEST_IMG_DIR = \"Datasets/Test/images/\"\n",
    "TEST_DEPTH_DIR = \"Datasets/Test/depths/\"\n",
    "\n",
    "IMAGE_HEIGHT = 120\n",
    "IMAGE_WIDTH = 160\n",
    "\n",
    "MODEL_NAME = 'Ynet_model'\n",
    "MODEL_SAVE_DIR = \"Models/Ynet/checkpoint/\"\n",
    "MODEL_LOAD_PATH = \"Models/Ynet/checkpoint/\" + MODEL_NAME + \"_10.pth.tar\"\n",
    "VALIDATION_IMAGES_SAVE_DIR = \"Models/Ynet/validation_outputs/\"\n",
    "\n",
    "dtype=torch.cuda.FloatTensor\n",
    "\n",
    "def train_unet(loader, model, optimizer, loss_fn, scaler):\n",
    "    # loop = tqdm(loader)\n",
    "\n",
    "    train_loss = 0\n",
    "    for batch_idx, (data, gradient, targets) in enumerate(loader):\n",
    "        data = data.to(device=DEVICE)\n",
    "        gradient = gradient.to(device=DEVICE)\n",
    "        targets = targets.to(device=DEVICE)\n",
    "\n",
    "        # forward\n",
    "        predictions = model(data.type(dtype), gradient.type(dtype))\n",
    "        loss = loss_fn(predictions, targets)\n",
    "\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # backward\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # scaler.scale(loss).backward()\n",
    "        # scaler.step(optimizer)\n",
    "        # scaler.update()\n",
    "\n",
    "        # update tqdm loop\n",
    "        # loop.set_postfix(loss=loss.item())\n",
    "\n",
    "    train_loss /= (batch_idx + 1)\n",
    "    return train_loss\n",
    "\n",
    "def validate_unet(loader, model, loss_fn, epoch, train_loss, save_folder):\n",
    "  # loop = tqdm(loader)\n",
    "\n",
    "  validation_loss = 0\n",
    "  scale_invariant_loss = 0\n",
    "  delta1_accuracy = 0\n",
    "  delta2_accuracy = 0\n",
    "  delta3_accuracy = 0\n",
    "  rmse_linear_loss = 0\n",
    "  rmse_log_loss = 0\n",
    "  abs_relative_difference_loss = 0\n",
    "  squared_relative_difference_loss = 0\n",
    "\n",
    "  model.eval()\n",
    "  for batch_idx, (data, gradient, targets) in enumerate(loader):\n",
    "      data = data.to(device=DEVICE)\n",
    "      gradient = gradient.to(device=DEVICE)\n",
    "      targets = targets.to(device=DEVICE)\n",
    "\n",
    "      with torch.no_grad():\n",
    "        predictions = model(data.type(dtype), gradient.type(dtype))\n",
    "        loss = loss_fn(predictions, targets)\n",
    "      \n",
    "      validation_loss += loss.item()\n",
    "\n",
    "      # Error function\n",
    "      scale_invariant_loss += loss_fn(predictions, targets)\n",
    "      delta1_accuracy += threeshold_percentage(predictions, targets, 1.25)\n",
    "      delta2_accuracy += threeshold_percentage(predictions, targets, 1.25*1.25)\n",
    "      delta3_accuracy += threeshold_percentage(predictions, targets, 1.25*1.25*1.25)\n",
    "      rmse_linear_loss += rmse_linear(predictions, targets)\n",
    "      rmse_log_loss += rmse_log(predictions, targets)\n",
    "      abs_relative_difference_loss += abs_relative_difference(predictions, targets)\n",
    "      squared_relative_difference_loss += squared_relative_difference(predictions, targets)\n",
    "\n",
    "      # Saving output depths\n",
    "      targets -= torch.min(targets)\n",
    "      targets = targets/torch.max(targets)\n",
    "\n",
    "      predictions -= torch.min(predictions)\n",
    "      predictions = predictions/torch.max(predictions)\n",
    "\n",
    "      torchvision.utils.save_image(predictions, f\"{save_folder}/pred_{batch_idx}.png\")\n",
    "      torchvision.utils.save_image(targets, f\"{save_folder}{batch_idx}.png\")\n",
    "      \n",
    "      # update tqdm loop\n",
    "      # loop.set_postfix(validation_loss=loss.item())\n",
    "  \n",
    "  validation_loss /= (batch_idx + 1)\n",
    "  delta1_accuracy /= (batch_idx + 1)\n",
    "  delta2_accuracy /= (batch_idx + 1)\n",
    "  delta3_accuracy /= (batch_idx + 1)\n",
    "  rmse_linear_loss /= (batch_idx + 1)\n",
    "  rmse_log_loss /= (batch_idx + 1)\n",
    "  abs_relative_difference_loss /= (batch_idx + 1)\n",
    "  squared_relative_difference_loss /= (batch_idx + 1)\n",
    "\n",
    "  print('Epoch: {}    {:.4f}      {:.4f}      {:.4f}      {:.4f}      {:.4f}      {:.4f}      {:.4f}      {:.4f}      {:.4f}'.format(epoch, train_loss, \n",
    "        validation_loss, delta1_accuracy, delta2_accuracy, delta3_accuracy, rmse_linear_loss, rmse_log_loss, \n",
    "        abs_relative_difference_loss, squared_relative_difference_loss))\n",
    "  \n",
    "  model.train()\n",
    "  return validation_loss\n",
    "\n",
    "def main():\n",
    "    rgb_data_transforms = transforms.Compose([\n",
    "        transforms.Resize((IMAGE_HEIGHT, IMAGE_WIDTH)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    depth_data_transforms = transforms.Compose([\n",
    "        TransposeDepthInput(),\n",
    "    ])\n",
    "\n",
    "    train_loader, val_loader, test_loader = get_loaders(\n",
    "          TRAIN_IMG_DIR,\n",
    "          TRAIN_DEPTH_DIR,\n",
    "          VAL_IMG_DIR,\n",
    "          VAL_DEPTH_DIR,\n",
    "          TEST_IMG_DIR,\n",
    "          TEST_DEPTH_DIR,\n",
    "          BATCH_SIZE,\n",
    "          rgb_data_transforms,\n",
    "          depth_data_transforms,\n",
    "          NUM_WORKERS,\n",
    "          PIN_MEMORY,\n",
    "    )\n",
    "\n",
    "    model = YNET(in_channels1=3, in_channels2=2, out_channels=1).to(DEVICE)\n",
    "    loss_fn = ScaleInvariantLoss\n",
    "    optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "    # scaler = torch.cuda.amp.GradScaler()\n",
    "    scaler = None\n",
    "    \n",
    "    train_losses, validation_losses = [], []\n",
    "\n",
    "    if LOAD_MODEL:\n",
    "      print(\"=> Loading Chekpoint\")\n",
    "      checkpoint = torch.load(MODEL_LOAD_PATH)\n",
    "      model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "      train_losses = checkpoint[\"train_losses\"]\n",
    "      validation_losses = checkpoint[\"validation_losses\"]\n",
    "      print(\"=> Checkpoint Loaded\")\n",
    "\n",
    "    print(\"********* Training the Unet Model **************\")\n",
    "    print(\"Epochs:     Train_loss  Val_loss    Delta_1     Delta_2     Delta_3    rmse_lin    rmse_log    abs_rel.  square_relative\")\n",
    "    print(\"Paper Val:                          (0.618)     (0.891)     (0.969)     (0.871)     (0.283)     (0.228)     (0.223)\")\n",
    "    \n",
    "    for epoch in range(1, NUM_EPOCHS+1):\n",
    "        train_loss = train_unet(train_loader, model, optimizer, loss_fn, scaler)\n",
    "        validation_loss = validate_unet(val_loader, model, loss_fn, epoch, train_loss, save_folder=VALIDATION_IMAGES_SAVE_DIR)\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        validation_losses.append(validation_loss)\n",
    "\n",
    "        if epoch % 10 == 0:\n",
    "          # save model\n",
    "          checkpoint = {\n",
    "              \"state_dict\": model.state_dict(),\n",
    "              \"train_losses\": train_losses,\n",
    "              \"validation_losses\": validation_losses,\n",
    "          }\n",
    "          save_path = MODEL_SAVE_DIR + MODEL_NAME + '_' + str(epoch) + '.pth.tar'\n",
    "          save_checkpoint(checkpoint, save_path)\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lpxupkCroTDK",
    "outputId": "f1908419-3ddc-49c6-e2e4-eb3d95d7e1d3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "********* Training the Unet Model **************\n",
      "Epochs:     Train_loss  Val_loss    Delta_1     Delta_2     Delta_3    rmse_lin    rmse_log    abs_rel.  square_relative\n",
      "Paper Val:                          (0.618)     (0.891)     (0.969)     (0.871)     (0.283)     (0.228)     (0.223)\n",
      "Epoch: 1    0.3414      0.1909      0.2447      0.5531      0.8189      1.1960      0.2718      0.4093      0.6139\n",
      "Epoch: 2    0.2244      0.1835      0.2566      0.5787      0.8241      1.1501      0.2617      0.4007      0.5793\n",
      "Epoch: 3    0.1929      0.1279      0.4537      0.7793      0.9304      0.9087      0.1581      0.3432      0.4893\n",
      "Epoch: 4    0.1780      0.1344      0.4015      0.7326      0.9181      0.9515      0.1770      0.3516      0.5106\n",
      "Epoch: 5    0.1662      0.1101      0.5621      0.8574      0.9590      0.7870      0.1261      0.3431      0.5537\n",
      "Epoch: 6    0.1571      0.1189      0.5442      0.8468      0.9549      0.8475      0.1371      0.3882      0.7987\n",
      "Epoch: 7    0.1506      0.1095      0.5450      0.8465      0.9543      0.7945      0.1278      0.3271      0.4872\n",
      "Epoch: 8    0.1460      0.1386      0.3956      0.7297      0.9105      0.9480      0.1812      0.3491      0.4858\n",
      "Epoch: 9    0.1370      0.1071      0.5682      0.8625      0.9602      0.7515      0.1231      0.3332      0.5387\n",
      "Epoch: 10    0.1317      0.1064      0.5757      0.8750      0.9638      0.7543      0.1215      0.3531      0.6255\n",
      "=> Saving checkpoint\n",
      "Epoch: 11    0.1275      0.1384      0.4495      0.7775      0.9201      0.9653      0.1823      0.5163      1.0104\n",
      "Epoch: 12    0.1191      0.1263      0.4584      0.7821      0.9316      0.8746      0.1586      0.3353      0.4831\n",
      "Epoch: 13    0.1127      0.1216      0.5462      0.8498      0.9508      0.8407      0.1421      0.4164      0.8133\n",
      "Epoch: 14    0.1079      0.1126      0.5500      0.8478      0.9509      0.7830      0.1316      0.3298      0.5142\n",
      "Epoch: 15    0.1002      0.1042      0.6001      0.8777      0.9618      0.7374      0.1190      0.3361      0.5682\n",
      "Epoch: 16    0.0930      0.1268      0.4541      0.7804      0.9319      0.8731      0.1612      0.3408      0.5108\n",
      "Epoch: 17    0.0924      0.1327      0.4447      0.7665      0.9213      0.9199      0.1687      0.3310      0.4674\n",
      "Epoch: 18    0.0860      0.1220      0.4845      0.7989      0.9375      0.8455      0.1514      0.3289      0.4906\n",
      "Epoch: 19    0.0831      0.1002      0.6150      0.8915      0.9685      0.7028      0.1130      0.3367      0.5967\n",
      "Epoch: 20    0.0784      0.1127      0.5855      0.8749      0.9606      0.7656      0.1256      0.3690      0.7242\n",
      "=> Saving checkpoint\n",
      "Epoch: 21    0.0781      0.1295      0.4567      0.7804      0.9271      0.8506      0.1631      0.3496      0.5559\n",
      "Epoch: 22    0.0728      0.0993      0.6221      0.8944      0.9666      0.7093      0.1115      0.3343      0.5773\n",
      "Epoch: 23    0.0712      0.1040      0.5905      0.8757      0.9614      0.7330      0.1179      0.3212      0.4882\n",
      "Epoch: 24    0.0697      0.1240      0.4841      0.7922      0.9325      0.8791      0.1533      0.3235      0.4530\n",
      "Epoch: 25    0.0662      0.1158      0.5041      0.8187      0.9447      0.8213      0.1405      0.3243      0.4759\n",
      "Epoch: 26    0.0609      0.1007      0.6002      0.8822      0.9669      0.7293      0.1138      0.3240      0.5387\n",
      "Epoch: 27    0.0609      0.1049      0.5842      0.8754      0.9634      0.7502      0.1192      0.3370      0.6010\n",
      "Epoch: 28    0.0570      0.0996      0.6283      0.8929      0.9654      0.7116      0.1120      0.3334      0.5778\n",
      "Epoch: 29    0.0552      0.1123      0.5475      0.8406      0.9516      0.7770      0.1332      0.3202      0.5003\n",
      "Epoch: 30    0.0526      0.1162      0.4764      0.8042      0.9409      0.8468      0.1462      0.3227      0.4609\n",
      "=> Saving checkpoint\n",
      "Epoch: 31    0.0508      0.0991      0.6207      0.8900      0.9641      0.7117      0.1111      0.3174      0.5223\n",
      "Epoch: 32    0.0496      0.1129      0.5086      0.8250      0.9485      0.8193      0.1380      0.3242      0.4947\n",
      "Epoch: 33    0.0474      0.1081      0.5362      0.8467      0.9571      0.7759      0.1291      0.3244      0.5135\n",
      "Epoch: 34    0.0445      0.1060      0.5908      0.8771      0.9642      0.7280      0.1197      0.3387      0.6259\n",
      "Epoch: 35    0.0454      0.1050      0.5499      0.8549      0.9601      0.7511      0.1247      0.3178      0.4902\n",
      "Epoch: 36    0.0428      0.0976      0.6247      0.8960      0.9686      0.7001      0.1100      0.3244      0.5588\n",
      "Epoch: 37    0.0412      0.0951      0.6171      0.8925      0.9683      0.7010      0.1081      0.3090      0.4924\n",
      "Epoch: 38    0.0406      0.0991      0.6155      0.8940      0.9688      0.7039      0.1116      0.3331      0.6238\n",
      "Epoch: 39    0.0383      0.0939      0.6449      0.9081      0.9720      0.6786      0.1051      0.3279      0.5914\n",
      "Epoch: 40    0.0379      0.1013      0.5793      0.8705      0.9613      0.7371      0.1178      0.3127      0.4884\n",
      "=> Saving checkpoint\n",
      "Epoch: 41    0.0369      0.1030      0.6223      0.8924      0.9626      0.7289      0.1178      0.3637      0.7170\n",
      "Epoch: 42    0.0358      0.1001      0.5918      0.8805      0.9629      0.7313      0.1150      0.3130      0.5004\n",
      "Epoch: 43    0.0336      0.0957      0.6145      0.8946      0.9695      0.6943      0.1089      0.3168      0.5393\n",
      "Epoch: 44    0.0344      0.0978      0.6100      0.8869      0.9669      0.7161      0.1113      0.3146      0.5273\n",
      "Epoch: 45    0.0326      0.1016      0.5936      0.8851      0.9697      0.7200      0.1146      0.3314      0.6121\n",
      "Epoch: 46    0.0312      0.1029      0.5398      0.8610      0.9613      0.7646      0.1235      0.3187      0.5089\n",
      "Epoch: 47    0.0317      0.0965      0.6047      0.8951      0.9706      0.7008      0.1100      0.3188      0.5470\n",
      "Epoch: 48    0.0309      0.0981      0.6124      0.8887      0.9667      0.7087      0.1115      0.3179      0.5406\n",
      "Epoch: 49    0.0292      0.0990      0.5705      0.8792      0.9664      0.7299      0.1162      0.3155      0.5141\n",
      "Epoch: 50    0.0281      0.0987      0.5963      0.8831      0.9670      0.7031      0.1133      0.3157      0.5239\n",
      "=> Saving checkpoint\n",
      "Epoch: 51    0.0290      0.0964      0.6106      0.8869      0.9684      0.7066      0.1111      0.3138      0.5292\n",
      "Epoch: 52    0.0284      0.0955      0.6312      0.8990      0.9685      0.6981      0.1078      0.3219      0.5505\n",
      "Epoch: 53    0.0273      0.0939      0.6390      0.9007      0.9702      0.6863      0.1060      0.3195      0.5531\n",
      "Epoch: 54    0.0261      0.0932      0.6172      0.9031      0.9715      0.6892      0.1060      0.3131      0.5234\n",
      "Epoch: 55    0.0269      0.0965      0.6027      0.8883      0.9696      0.7079      0.1110      0.3154      0.5290\n",
      "Epoch: 56    0.0258      0.0934      0.6233      0.8969      0.9688      0.6955      0.1070      0.3054      0.4912\n",
      "Epoch: 57    0.0270      0.0973      0.6318      0.8963      0.9688      0.7035      0.1084      0.3229      0.5716\n",
      "Epoch: 58    0.0266      0.0972      0.6111      0.8887      0.9676      0.7005      0.1109      0.3121      0.5212\n",
      "Epoch: 59    0.0267      0.0935      0.6328      0.8997      0.9714      0.6848      0.1061      0.3143      0.5401\n",
      "Epoch: 60    0.0247      0.0933      0.6396      0.9064      0.9725      0.6761      0.1048      0.3186      0.5537\n",
      "=> Saving checkpoint\n",
      "Epoch: 61    0.0245      0.0938      0.6122      0.8959      0.9687      0.6981      0.1076      0.3062      0.4962\n",
      "Epoch: 62    0.0240      0.0972      0.5780      0.8794      0.9662      0.7338      0.1137      0.3079      0.4783\n",
      "Epoch: 63    0.0240      0.0972      0.6040      0.8883      0.9675      0.7151      0.1113      0.3141      0.5161\n",
      "Epoch: 64    0.0234      0.0935      0.6255      0.8986      0.9722      0.6864      0.1062      0.3115      0.5307\n",
      "Epoch: 65    0.0228      0.0963      0.6257      0.8949      0.9700      0.6959      0.1085      0.3224      0.5752\n",
      "Epoch: 66    0.0232      0.0946      0.6096      0.8915      0.9689      0.7056      0.1085      0.3105      0.5026\n",
      "Epoch: 67    0.0225      0.0942      0.6211      0.9024      0.9725      0.6872      0.1066      0.3189      0.5531\n",
      "Epoch: 68    0.0231      0.0970      0.5976      0.8860      0.9655      0.7199      0.1116      0.3095      0.4869\n",
      "Epoch: 69    0.0226      0.0956      0.6052      0.8863      0.9688      0.7073      0.1103      0.3067      0.4876\n",
      "Epoch: 70    0.0225      0.0972      0.5976      0.8879      0.9663      0.7171      0.1122      0.3139      0.5254\n",
      "=> Saving checkpoint\n",
      "Epoch: 71    0.0214      0.0923      0.6311      0.9045      0.9728      0.6819      0.1049      0.3133      0.5431\n",
      "Epoch: 72    0.0206      0.0996      0.5604      0.8700      0.9630      0.7493      0.1188      0.3122      0.4781\n",
      "Epoch: 73    0.0203      0.0921      0.6485      0.9059      0.9707      0.6792      0.1037      0.3180      0.5485\n",
      "Epoch: 74    0.0205      0.0948      0.6134      0.8939      0.9704      0.7082      0.1082      0.3111      0.5164\n",
      "Epoch: 75    0.0212      0.0973      0.6067      0.8886      0.9653      0.7235      0.1108      0.3109      0.4948\n",
      "Epoch: 76    0.0211      0.0945      0.6178      0.8958      0.9684      0.7011      0.1082      0.3100      0.4979\n",
      "Epoch: 77    0.0206      0.0933      0.6095      0.8971      0.9720      0.6921      0.1076      0.3110      0.5069\n",
      "Epoch: 78    0.0206      0.0908      0.6500      0.9066      0.9721      0.6709      0.1021      0.3079      0.5055\n",
      "Epoch: 79    0.0207      0.0935      0.6496      0.9068      0.9726      0.6718      0.1050      0.3294      0.6058\n",
      "Epoch: 80    0.0194      0.0949      0.6169      0.8924      0.9697      0.6979      0.1086      0.3080      0.5059\n",
      "=> Saving checkpoint\n",
      "Epoch: 81    0.0208      0.1015      0.5739      0.8732      0.9679      0.7177      0.1185      0.3231      0.5571\n",
      "Epoch: 82    0.0201      0.0954      0.6417      0.9000      0.9692      0.6916      0.1070      0.3217      0.5646\n",
      "Epoch: 83    0.0203      0.0924      0.6308      0.9014      0.9711      0.6823      0.1048      0.3120      0.5135\n",
      "Epoch: 84    0.0189      0.0977      0.5702      0.8789      0.9668      0.7363      0.1156      0.3140      0.4960\n",
      "Epoch: 85    0.0192      0.0921      0.6485      0.9074      0.9714      0.6700      0.1035      0.3126      0.5432\n",
      "Epoch: 86    0.0181      0.0961      0.5934      0.8863      0.9684      0.7099      0.1118      0.3110      0.5039\n",
      "Epoch: 87    0.0180      0.0984      0.5795      0.8759      0.9677      0.7169      0.1155      0.3144      0.5164\n",
      "Epoch: 88    0.0183      0.0940      0.6157      0.8967      0.9703      0.6912      0.1080      0.3132      0.5245\n",
      "Epoch: 89    0.0184      0.0931      0.6130      0.8952      0.9707      0.6965      0.1074      0.3077      0.4944\n",
      "Epoch: 90    0.0173      0.0947      0.6487      0.9072      0.9702      0.6758      0.1080      0.3442      0.6492\n",
      "=> Saving checkpoint\n",
      "Epoch: 91    0.0178      0.0921      0.6620      0.9143      0.9732      0.6614      0.1034      0.3341      0.6456\n",
      "Epoch: 92    0.0169      0.0893      0.6487      0.9100      0.9743      0.6634      0.1008      0.3083      0.5192\n",
      "Epoch: 93    0.0165      0.0945      0.6253      0.8949      0.9697      0.6947      0.1074      0.3101      0.5010\n",
      "Epoch: 94    0.0165      0.1010      0.5773      0.8763      0.9679      0.7188      0.1169      0.3241      0.5674\n",
      "Epoch: 95    0.0178      0.0946      0.5955      0.8898      0.9694      0.7087      0.1098      0.3086      0.4941\n",
      "Epoch: 96    0.0171      0.0913      0.6557      0.9095      0.9712      0.6616      0.1028      0.3213      0.5633\n",
      "Epoch: 97    0.0163      0.0938      0.6374      0.9038      0.9722      0.6771      0.1061      0.3226      0.5920\n",
      "Epoch: 98    0.0159      0.0908      0.6536      0.9098      0.9734      0.6602      0.1021      0.3171      0.5487\n",
      "Epoch: 99    0.0156      0.0922      0.6498      0.9051      0.9717      0.6713      0.1037      0.3146      0.5414\n",
      "Epoch: 100    0.0155      0.0900      0.6560      0.9092      0.9725      0.6652      0.1009      0.3074      0.5118\n",
      "=> Saving checkpoint\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rhjAKIoDwKxo"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "tlgm7T_jwK5U"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ICzn4lbDxdrk"
   },
   "source": [
    "### **Testing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "XfE4MfUbxdKK",
    "outputId": "c4b69544-b39a-4027-d384-ab2e777a9718"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/content/drive/MyDrive/Neural Network Project\n"
     ]
    }
   ],
   "source": [
    "%cd /content/drive/MyDrive/Neural\\ Network\\ Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "uhLkY0c1xdKP"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import torchvision.transforms as transforms\n",
    "import torch\n",
    "from Ynet import YNET\n",
    "from DataLoader import TransposeDepthInput, NYUDataset, save_checkpoint, get_loaders, save_predictions_as_imgs\n",
    "from metrics import ScaleInvariantLoss, threeshold_percentage, rmse_linear, rmse_log, abs_relative_difference, squared_relative_difference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mp1PIEApxhHQ"
   },
   "outputs": [],
   "source": [
    "IMAGE_HEIGHT = 120\n",
    "IMAGE_WIDTH = 160\n",
    "\n",
    "rgb_data_transforms = transforms.Compose([\n",
    "    transforms.Resize((IMAGE_HEIGHT, IMAGE_WIDTH)),\n",
    "    transforms.ToTensor(),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "pzQsrws-xhPO",
    "outputId": "aac9b020-4911-4002-f53e-0ea032461d15"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "DEVICE = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "YNET_MODEL_PATH = \"Models/Ynet/checkpoint/Ynet_model_100.pth.tar\"\n",
    "TRAIN_SAVE_PATH = \"Models/Ynet/predictions/Train/\"\n",
    "VAL_SAVE_PATH = \"Models/Ynet/predictions/Validation/\"\n",
    "TEST_SAVE_PATH = \"Models/Ynet/predictions/Test/\"\n",
    "\n",
    "TRAIN_IMG_DIR = \"Datasets/Train/images/\"\n",
    "TRAIN_DEPTH_DIR = \"Datasets/Train/depths/\"\n",
    "VAL_IMG_DIR = \"Datasets/Validation/images/\"\n",
    "VAL_DEPTH_DIR = \"Datasets/Validation/depths/\"\n",
    "TEST_IMG_DIR = \"Datasets/Test/images/\"\n",
    "TEST_DEPTH_DIR = \"Datasets/Test/depths/\"\n",
    "\n",
    "model = YNET(in_channels1=3, in_channels2=2, out_channels=1).to(DEVICE)\n",
    "\n",
    "# Loading Unet model\n",
    "checkpoint = torch.load(YNET_MODEL_PATH)\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "_hv_32ZF143-"
   },
   "outputs": [],
   "source": [
    "def Save_Predictions(image_dir, depth_dir, save_dir):\n",
    "    model.eval()\n",
    "    for image_name in os.listdir(image_dir):\n",
    "        # Load the image and dpeth\n",
    "        image = cv2.imread(image_dir + image_name, cv2.IMREAD_UNCHANGED)\n",
    "        depth = cv2.imread(depth_dir+ image_name, cv2.IMREAD_UNCHANGED)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        image = Image.fromarray(image)\n",
    "        image = rgb_data_transforms(image)\n",
    "\n",
    "        # Find the gradient\n",
    "        gray = np.moveaxis(image.numpy(), [0, 1, 2], [2, 0, 1])\n",
    "        gray = cv2.cvtColor(gray, cv2.COLOR_BGR2GRAY)\n",
    "        gx = cv2.Sobel(gray, ddepth = cv2.CV_32F, dx=1, dy=0, ksize=3)\n",
    "        gy = cv2.Sobel(gray, ddepth = cv2.CV_32F, dx=0, dy=1, ksize=3)\n",
    "        gradient = torch.from_numpy(np.stack([gx, gy]))\n",
    "\n",
    "        image = torch.unsqueeze(image, 0)\n",
    "        gradient = torch.unsqueeze(gradient, 0)\n",
    "\n",
    "        # Predict the output\n",
    "        image = image.to(device=DEVICE)\n",
    "        gradient = gradient.to(device=DEVICE)\n",
    "        with torch.no_grad():\n",
    "            predicted = model(image, gradient)\n",
    "\n",
    "        image = image.cpu()\n",
    "        predicted = predicted.cpu()\n",
    "\n",
    "        input_image = np.zeros((120, 160, 3), dtype=np.float32)\n",
    "        input_image[:, :, 0] = image[0, 0, :, :]\n",
    "        input_image[:, :, 1] = image[0, 1, :, :]\n",
    "        input_image[:, :, 2] = image[0, 2, :, :]\n",
    "        predicted = predicted[0, 0, :, :]\n",
    "\n",
    "        fig = plt.figure(figsize=(14, 6))\n",
    "\n",
    "        ax = fig.add_subplot(1, 3, 1)\n",
    "        ax.set_title('Input image')\n",
    "        plt.imshow(input_image)\n",
    "        ax = fig.add_subplot(1, 3, 2)\n",
    "        ax.set_title('Ground truth')\n",
    "        plt.imshow(depth, cmap='gist_gray')    #plt.imshow(actual_depth, cmap='jet')\n",
    "        ax = fig.add_subplot(1, 3, 3)\n",
    "        ax.set_title('Ynet predicted')\n",
    "        plt.imshow(predicted, cmap='gist_gray')\n",
    "        plt.savefig(f'{save_dir}/{image_name}')\n",
    "        plt.close(fig)\n",
    "    model.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "n2hLrZ2j1xEi"
   },
   "outputs": [],
   "source": [
    "Save_Predictions(VAL_IMG_DIR, VAL_DEPTH_DIR, VAL_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vBlw9zbz-Jlb"
   },
   "outputs": [],
   "source": [
    "Save_Predictions(TRAIN_IMG_DIR, TRAIN_DEPTH_DIR, TRAIN_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "I3e4lIbu34u9"
   },
   "outputs": [],
   "source": [
    "Save_Predictions(TEST_IMG_DIR, TEST_DEPTH_DIR, TEST_SAVE_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "TFk9KCDK8H44"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "q1lP_oP4QJ_u"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y8aUbM_6OUZh"
   },
   "source": [
    "### **Time taken**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YUCw66JVOT6q",
    "outputId": "bfae0a2c-32cb-447f-9193-406ec03ba4c3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken: 0.11453585147857666\n",
      "Time taken: 0.010718274116516113\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "model.eval()\n",
    "start_time = time.time()\n",
    "num_images = 50\n",
    "total_time = 0\n",
    "for i in range(num_images):\n",
    "    image = cv2.imread(TRAIN_IMG_DIR + str(i) + '.png', cv2.IMREAD_UNCHANGED)\n",
    "    depth = cv2.imread(TRAIN_DEPTH_DIR + str(i) + '.png', cv2.IMREAD_UNCHANGED)\n",
    "    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    image = Image.fromarray(image)\n",
    "    image = rgb_data_transforms(image)\n",
    "\n",
    "    # Find the gradient\n",
    "    gray = np.moveaxis(image.numpy(), [0, 1, 2], [2, 0, 1])\n",
    "    gray = cv2.cvtColor(gray, cv2.COLOR_BGR2GRAY)\n",
    "    gx = cv2.Sobel(gray, ddepth = cv2.CV_32F, dx=1, dy=0, ksize=3)\n",
    "    gy = cv2.Sobel(gray, ddepth = cv2.CV_32F, dx=0, dy=1, ksize=3)\n",
    "    gradient = torch.from_numpy(np.stack([gx, gy]))\n",
    "\n",
    "    image = torch.unsqueeze(image, 0)\n",
    "    gradient = torch.unsqueeze(gradient, 0)\n",
    "\n",
    "    # Predict the output\n",
    "    image = image.to(device=DEVICE)\n",
    "    gradient = gradient.to(device=DEVICE)\n",
    "    with torch.no_grad():\n",
    "        start_time1 = time.time()\n",
    "        predicted = model(image, gradient)\n",
    "        end_time1 = time.time()\n",
    "    total_time += (end_time1-start_time1)\n",
    "end_time = time.time()\n",
    "model.train()\n",
    "print('Time taken:', (end_time-start_time)/num_images)\n",
    "print('Time taken:', (total_time)/num_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T7V-jG1QQw9r"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JGN0O-RLQxAB"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Gx7Ry4e2Qxie"
   },
   "source": [
    "### **Model summary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cpNZk-K8SGus",
    "outputId": "d5878674-e01c-423e-ff90-b7f3033375a0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YNET(\n",
      "  (ups): ModuleList()\n",
      "  (downConvs1): DownConv(\n",
      "    (downs): ModuleList(\n",
      "      (0): DoubleConv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (1): DoubleConv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (2): DoubleConv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (3): DoubleConv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (residualBlocks): ModuleList(\n",
      "      (0): DoubleConv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=same, bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=same, bias=False)\n",
      "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (1): DoubleConv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=same, bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=same, bias=False)\n",
      "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (2): DoubleConv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=same, bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=same, bias=False)\n",
      "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (3): DoubleConv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=same, bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=same, bias=False)\n",
      "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (downConvs2): DownConv(\n",
      "    (downs): ModuleList(\n",
      "      (0): DoubleConv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (1): DoubleConv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (2): DoubleConv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (3): DoubleConv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (residualBlocks): ModuleList(\n",
      "      (0): DoubleConv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=same, bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=same, bias=False)\n",
      "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (1): DoubleConv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=same, bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=same, bias=False)\n",
      "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (2): DoubleConv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=same, bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=same, bias=False)\n",
      "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (3): DoubleConv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=same, bias=False)\n",
      "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=same, bias=False)\n",
      "          (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  )\n",
      "  (bottleneck): DoubleConv(\n",
      "    (conv): Sequential(\n",
      "      (0): Conv2d(1024, 512, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "      (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (2): ReLU(inplace=True)\n",
      "      (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "      (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (5): ReLU(inplace=True)\n",
      "    )\n",
      "  )\n",
      "  (upConvs): UpConv(\n",
      "    (ups): ModuleList(\n",
      "      (0): ConvTranspose2d(512, 512, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (1): DoubleConv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(1536, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "          (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (2): ConvTranspose2d(256, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (3): DoubleConv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(768, 128, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "          (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (4): ConvTranspose2d(128, 128, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (5): DoubleConv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(384, 64, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "          (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "          (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "      (6): ConvTranspose2d(64, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "      (7): DoubleConv(\n",
      "        (conv): Sequential(\n",
      "          (0): Conv2d(192, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "          (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (2): ReLU(inplace=True)\n",
      "          (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "          (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (5): ReLU(inplace=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (downConvs1): DownConv(\n",
      "      (downs): ModuleList(\n",
      "        (0): DoubleConv(\n",
      "          (conv): Sequential(\n",
      "            (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (1): DoubleConv(\n",
      "          (conv): Sequential(\n",
      "            (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (2): DoubleConv(\n",
      "          (conv): Sequential(\n",
      "            (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (3): DoubleConv(\n",
      "          (conv): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (residualBlocks): ModuleList(\n",
      "        (0): DoubleConv(\n",
      "          (conv): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=same, bias=False)\n",
      "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=same, bias=False)\n",
      "            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (1): DoubleConv(\n",
      "          (conv): Sequential(\n",
      "            (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=same, bias=False)\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=same, bias=False)\n",
      "            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (2): DoubleConv(\n",
      "          (conv): Sequential(\n",
      "            (0): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=same, bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=same, bias=False)\n",
      "            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (3): DoubleConv(\n",
      "          (conv): Sequential(\n",
      "            (0): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=same, bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=same, bias=False)\n",
      "            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "    (downConvs2): DownConv(\n",
      "      (downs): ModuleList(\n",
      "        (0): DoubleConv(\n",
      "          (conv): Sequential(\n",
      "            (0): Conv2d(2, 64, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (1): DoubleConv(\n",
      "          (conv): Sequential(\n",
      "            (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (2): DoubleConv(\n",
      "          (conv): Sequential(\n",
      "            (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (3): DoubleConv(\n",
      "          (conv): Sequential(\n",
      "            (0): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=same, bias=False)\n",
      "            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (residualBlocks): ModuleList(\n",
      "        (0): DoubleConv(\n",
      "          (conv): Sequential(\n",
      "            (0): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=same, bias=False)\n",
      "            (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(64, 64, kernel_size=(5, 5), stride=(1, 1), padding=same, bias=False)\n",
      "            (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (1): DoubleConv(\n",
      "          (conv): Sequential(\n",
      "            (0): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=same, bias=False)\n",
      "            (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(128, 128, kernel_size=(5, 5), stride=(1, 1), padding=same, bias=False)\n",
      "            (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (2): DoubleConv(\n",
      "          (conv): Sequential(\n",
      "            (0): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=same, bias=False)\n",
      "            (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(256, 256, kernel_size=(5, 5), stride=(1, 1), padding=same, bias=False)\n",
      "            (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "        (3): DoubleConv(\n",
      "          (conv): Sequential(\n",
      "            (0): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=same, bias=False)\n",
      "            (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (2): ReLU(inplace=True)\n",
      "            (3): Conv2d(512, 512, kernel_size=(5, 5), stride=(1, 1), padding=same, bias=False)\n",
      "            (4): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "            (5): ReLU(inplace=True)\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    )\n",
      "  )\n",
      "  (final_conv): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "uw4ztdEZQy3-",
    "outputId": "5741e426-3d17-45b3-f412-5d3391a1bd9b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------------------------------+------------+\n",
      "|                  Modules                  | Parameters |\n",
      "+-------------------------------------------+------------+\n",
      "|      downConvs1.downs.0.conv.0.weight     |    1728    |\n",
      "|      downConvs1.downs.0.conv.1.weight     |     64     |\n",
      "|       downConvs1.downs.0.conv.1.bias      |     64     |\n",
      "|      downConvs1.downs.0.conv.3.weight     |   36864    |\n",
      "|      downConvs1.downs.0.conv.4.weight     |     64     |\n",
      "|       downConvs1.downs.0.conv.4.bias      |     64     |\n",
      "|      downConvs1.downs.1.conv.0.weight     |   73728    |\n",
      "|      downConvs1.downs.1.conv.1.weight     |    128     |\n",
      "|       downConvs1.downs.1.conv.1.bias      |    128     |\n",
      "|      downConvs1.downs.1.conv.3.weight     |   147456   |\n",
      "|      downConvs1.downs.1.conv.4.weight     |    128     |\n",
      "|       downConvs1.downs.1.conv.4.bias      |    128     |\n",
      "|      downConvs1.downs.2.conv.0.weight     |   294912   |\n",
      "|      downConvs1.downs.2.conv.1.weight     |    256     |\n",
      "|       downConvs1.downs.2.conv.1.bias      |    256     |\n",
      "|      downConvs1.downs.2.conv.3.weight     |   589824   |\n",
      "|      downConvs1.downs.2.conv.4.weight     |    256     |\n",
      "|       downConvs1.downs.2.conv.4.bias      |    256     |\n",
      "|      downConvs1.downs.3.conv.0.weight     |  1179648   |\n",
      "|      downConvs1.downs.3.conv.1.weight     |    512     |\n",
      "|       downConvs1.downs.3.conv.1.bias      |    512     |\n",
      "|      downConvs1.downs.3.conv.3.weight     |  2359296   |\n",
      "|      downConvs1.downs.3.conv.4.weight     |    512     |\n",
      "|       downConvs1.downs.3.conv.4.bias      |    512     |\n",
      "| downConvs1.residualBlocks.0.conv.0.weight |   102400   |\n",
      "| downConvs1.residualBlocks.0.conv.1.weight |     64     |\n",
      "|  downConvs1.residualBlocks.0.conv.1.bias  |     64     |\n",
      "| downConvs1.residualBlocks.0.conv.3.weight |   102400   |\n",
      "| downConvs1.residualBlocks.0.conv.4.weight |     64     |\n",
      "|  downConvs1.residualBlocks.0.conv.4.bias  |     64     |\n",
      "| downConvs1.residualBlocks.1.conv.0.weight |   409600   |\n",
      "| downConvs1.residualBlocks.1.conv.1.weight |    128     |\n",
      "|  downConvs1.residualBlocks.1.conv.1.bias  |    128     |\n",
      "| downConvs1.residualBlocks.1.conv.3.weight |   409600   |\n",
      "| downConvs1.residualBlocks.1.conv.4.weight |    128     |\n",
      "|  downConvs1.residualBlocks.1.conv.4.bias  |    128     |\n",
      "| downConvs1.residualBlocks.2.conv.0.weight |  1638400   |\n",
      "| downConvs1.residualBlocks.2.conv.1.weight |    256     |\n",
      "|  downConvs1.residualBlocks.2.conv.1.bias  |    256     |\n",
      "| downConvs1.residualBlocks.2.conv.3.weight |  1638400   |\n",
      "| downConvs1.residualBlocks.2.conv.4.weight |    256     |\n",
      "|  downConvs1.residualBlocks.2.conv.4.bias  |    256     |\n",
      "| downConvs1.residualBlocks.3.conv.0.weight |  6553600   |\n",
      "| downConvs1.residualBlocks.3.conv.1.weight |    512     |\n",
      "|  downConvs1.residualBlocks.3.conv.1.bias  |    512     |\n",
      "| downConvs1.residualBlocks.3.conv.3.weight |  6553600   |\n",
      "| downConvs1.residualBlocks.3.conv.4.weight |    512     |\n",
      "|  downConvs1.residualBlocks.3.conv.4.bias  |    512     |\n",
      "|      downConvs2.downs.0.conv.0.weight     |    1152    |\n",
      "|      downConvs2.downs.0.conv.1.weight     |     64     |\n",
      "|       downConvs2.downs.0.conv.1.bias      |     64     |\n",
      "|      downConvs2.downs.0.conv.3.weight     |   36864    |\n",
      "|      downConvs2.downs.0.conv.4.weight     |     64     |\n",
      "|       downConvs2.downs.0.conv.4.bias      |     64     |\n",
      "|      downConvs2.downs.1.conv.0.weight     |   73728    |\n",
      "|      downConvs2.downs.1.conv.1.weight     |    128     |\n",
      "|       downConvs2.downs.1.conv.1.bias      |    128     |\n",
      "|      downConvs2.downs.1.conv.3.weight     |   147456   |\n",
      "|      downConvs2.downs.1.conv.4.weight     |    128     |\n",
      "|       downConvs2.downs.1.conv.4.bias      |    128     |\n",
      "|      downConvs2.downs.2.conv.0.weight     |   294912   |\n",
      "|      downConvs2.downs.2.conv.1.weight     |    256     |\n",
      "|       downConvs2.downs.2.conv.1.bias      |    256     |\n",
      "|      downConvs2.downs.2.conv.3.weight     |   589824   |\n",
      "|      downConvs2.downs.2.conv.4.weight     |    256     |\n",
      "|       downConvs2.downs.2.conv.4.bias      |    256     |\n",
      "|      downConvs2.downs.3.conv.0.weight     |  1179648   |\n",
      "|      downConvs2.downs.3.conv.1.weight     |    512     |\n",
      "|       downConvs2.downs.3.conv.1.bias      |    512     |\n",
      "|      downConvs2.downs.3.conv.3.weight     |  2359296   |\n",
      "|      downConvs2.downs.3.conv.4.weight     |    512     |\n",
      "|       downConvs2.downs.3.conv.4.bias      |    512     |\n",
      "| downConvs2.residualBlocks.0.conv.0.weight |   102400   |\n",
      "| downConvs2.residualBlocks.0.conv.1.weight |     64     |\n",
      "|  downConvs2.residualBlocks.0.conv.1.bias  |     64     |\n",
      "| downConvs2.residualBlocks.0.conv.3.weight |   102400   |\n",
      "| downConvs2.residualBlocks.0.conv.4.weight |     64     |\n",
      "|  downConvs2.residualBlocks.0.conv.4.bias  |     64     |\n",
      "| downConvs2.residualBlocks.1.conv.0.weight |   409600   |\n",
      "| downConvs2.residualBlocks.1.conv.1.weight |    128     |\n",
      "|  downConvs2.residualBlocks.1.conv.1.bias  |    128     |\n",
      "| downConvs2.residualBlocks.1.conv.3.weight |   409600   |\n",
      "| downConvs2.residualBlocks.1.conv.4.weight |    128     |\n",
      "|  downConvs2.residualBlocks.1.conv.4.bias  |    128     |\n",
      "| downConvs2.residualBlocks.2.conv.0.weight |  1638400   |\n",
      "| downConvs2.residualBlocks.2.conv.1.weight |    256     |\n",
      "|  downConvs2.residualBlocks.2.conv.1.bias  |    256     |\n",
      "| downConvs2.residualBlocks.2.conv.3.weight |  1638400   |\n",
      "| downConvs2.residualBlocks.2.conv.4.weight |    256     |\n",
      "|  downConvs2.residualBlocks.2.conv.4.bias  |    256     |\n",
      "| downConvs2.residualBlocks.3.conv.0.weight |  6553600   |\n",
      "| downConvs2.residualBlocks.3.conv.1.weight |    512     |\n",
      "|  downConvs2.residualBlocks.3.conv.1.bias  |    512     |\n",
      "| downConvs2.residualBlocks.3.conv.3.weight |  6553600   |\n",
      "| downConvs2.residualBlocks.3.conv.4.weight |    512     |\n",
      "|  downConvs2.residualBlocks.3.conv.4.bias  |    512     |\n",
      "|          bottleneck.conv.0.weight         |  4718592   |\n",
      "|          bottleneck.conv.1.weight         |    512     |\n",
      "|           bottleneck.conv.1.bias          |    512     |\n",
      "|          bottleneck.conv.3.weight         |  2359296   |\n",
      "|          bottleneck.conv.4.weight         |    512     |\n",
      "|           bottleneck.conv.4.bias          |    512     |\n",
      "|            upConvs.ups.0.weight           |  1048576   |\n",
      "|             upConvs.ups.0.bias            |    512     |\n",
      "|        upConvs.ups.1.conv.0.weight        |  3538944   |\n",
      "|        upConvs.ups.1.conv.1.weight        |    256     |\n",
      "|         upConvs.ups.1.conv.1.bias         |    256     |\n",
      "|        upConvs.ups.1.conv.3.weight        |   589824   |\n",
      "|        upConvs.ups.1.conv.4.weight        |    256     |\n",
      "|         upConvs.ups.1.conv.4.bias         |    256     |\n",
      "|            upConvs.ups.2.weight           |   262144   |\n",
      "|             upConvs.ups.2.bias            |    256     |\n",
      "|        upConvs.ups.3.conv.0.weight        |   884736   |\n",
      "|        upConvs.ups.3.conv.1.weight        |    128     |\n",
      "|         upConvs.ups.3.conv.1.bias         |    128     |\n",
      "|        upConvs.ups.3.conv.3.weight        |   147456   |\n",
      "|        upConvs.ups.3.conv.4.weight        |    128     |\n",
      "|         upConvs.ups.3.conv.4.bias         |    128     |\n",
      "|            upConvs.ups.4.weight           |   65536    |\n",
      "|             upConvs.ups.4.bias            |    128     |\n",
      "|        upConvs.ups.5.conv.0.weight        |   221184   |\n",
      "|        upConvs.ups.5.conv.1.weight        |     64     |\n",
      "|         upConvs.ups.5.conv.1.bias         |     64     |\n",
      "|        upConvs.ups.5.conv.3.weight        |   36864    |\n",
      "|        upConvs.ups.5.conv.4.weight        |     64     |\n",
      "|         upConvs.ups.5.conv.4.bias         |     64     |\n",
      "|            upConvs.ups.6.weight           |   16384    |\n",
      "|             upConvs.ups.6.bias            |     64     |\n",
      "|        upConvs.ups.7.conv.0.weight        |   55296    |\n",
      "|        upConvs.ups.7.conv.1.weight        |     32     |\n",
      "|         upConvs.ups.7.conv.1.bias         |     32     |\n",
      "|        upConvs.ups.7.conv.3.weight        |    9216    |\n",
      "|        upConvs.ups.7.conv.4.weight        |     32     |\n",
      "|         upConvs.ups.7.conv.4.bias         |     32     |\n",
      "|             final_conv.weight             |     32     |\n",
      "|              final_conv.bias              |     1      |\n",
      "+-------------------------------------------+------------+\n",
      "Total Trainable Params: 58156705\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "58156705"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from prettytable import PrettyTable\n",
    "\n",
    "def count_parameters(model):\n",
    "    table = PrettyTable([\"Modules\", \"Parameters\"])\n",
    "    total_params = 0\n",
    "    for name, parameter in model.named_parameters():\n",
    "        if not parameter.requires_grad: continue\n",
    "        param = parameter.numel()\n",
    "        table.add_row([name, param])\n",
    "        total_params+=param\n",
    "    print(table)\n",
    "    print(f\"Total Trainable Params: {total_params}\")\n",
    "    return total_params\n",
    "    \n",
    "count_parameters(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "24-hoc8fVYUG"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Y Net.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
